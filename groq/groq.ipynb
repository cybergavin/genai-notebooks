{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "704f43c0-b52b-4247-8a82-dde225de4622",
   "metadata": {},
   "source": [
    "# Groq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15233d4f-65f5-4355-817d-bef5926f1a34",
   "metadata": {},
   "source": [
    "[Groq](https://groq.com/about-us/) is a company founded in 2016, that focuses on fast AI inference. Currently (26-Jan-25), Groq does not have any of their own models, but provides very fast inferencing for open source foundation models, with their custom-built [Language Processing Units (LPUs)](https://groq.com/wp-content/uploads/2024/07/GroqThoughts_WhatIsALPU-vF.pdf) powering their [cloud](https://groq.com/groqcloud/) and [compute cluster](https://groq.com/groqrack/) hardware products."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ceec5b-1cec-4de8-80be-f37d8506ff63",
   "metadata": {},
   "source": [
    "# Getting started with the SDK (Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7d6173-1259-4a61-9cb8-2af483eab96a",
   "metadata": {},
   "source": [
    "### STEP 1: Get an API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a277347-2083-4daa-a327-1426aeb8da40",
   "metadata": {},
   "source": [
    "Get an API key for using Groq APIs from [here](https://console.groq.com/keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adf6756-6b03-4b6c-8b8b-38e87270375f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### STEP 2: Install client libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fd0d41-b084-4ed2-8d6a-5049fcfdff93",
   "metadata": {},
   "source": [
    "The [Groq Python library](https://console.groq.com/docs/libraries) provides convenient access to the Groq REST API from any Python 3.7+ application. The library includes type definitions for all request params and response fields, and offers both synchronous and asynchronous clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1dc053-68d0-4ff0-8eed-5d869a383d18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install groq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65758ecd-064d-4e58-a66c-cfc1a98ba9fb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdeef18-f48e-4baa-9162-f520a1498d4c",
   "metadata": {},
   "source": [
    "### STEP 3: Configure environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39241621-42e9-44ce-80e7-cde5c32409a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = getpass(\"Enter your Groq API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb577880-3788-4745-af49-f00665dcc717",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aebe972-e1f2-442c-b463-622427092238",
   "metadata": {},
   "source": [
    "### STEP 4: Use the API and SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17afa99f-10c7-420a-af98-a2528606d959",
   "metadata": {},
   "source": [
    "**Example 1:** List all models supported by Groq (API call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0307e8c3-b9f3-48c6-b2e9-93a04d54020c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c74a3cb2-54fa-4f9b-bfbc-9452f72436bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+-----------------+--------+----------------+\n",
      "|            Model ID           |     Owned By    | Active | Context Window |\n",
      "+-------------------------------+-----------------+--------+----------------+\n",
      "|      llama-3.2-3b-preview     |       Meta      |  True  |      8192      |\n",
      "|  llama-3.2-90b-vision-preview |       Meta      |  True  |      8192      |\n",
      "| deepseek-r1-distill-llama-70b | DeepSeek / Meta |  True  |     131072     |\n",
      "|      llama-3.2-1b-preview     |       Meta      |  True  |      8192      |\n",
      "|       mixtral-8x7b-32768      |    Mistral AI   |  True  |     32768      |\n",
      "|   distil-whisper-large-v3-en  |   Hugging Face  |  True  |      448       |\n",
      "|    llama-3.3-70b-versatile    |       Meta      |  True  |     32768      |\n",
      "|        llama-guard-3-8b       |       Meta      |  True  |      8192      |\n",
      "|         llama3-8b-8192        |       Meta      |  True  |      8192      |\n",
      "|     llama-3.3-70b-specdec     |       Meta      |  True  |      8192      |\n",
      "|        whisper-large-v3       |      OpenAI     |  True  |      448       |\n",
      "|      llama-3.1-8b-instant     |       Meta      |  True  |     131072     |\n",
      "|          gemma2-9b-it         |      Google     |  True  |      8192      |\n",
      "|  llama-3.2-11b-vision-preview |       Meta      |  True  |      8192      |\n",
      "|     whisper-large-v3-turbo    |      OpenAI     |  True  |      448       |\n",
      "|        llama3-70b-8192        |       Meta      |  True  |      8192      |\n",
      "+-------------------------------+-----------------+--------+----------------+\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "url = \"https://api.groq.com/openai/v1/models\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {os.environ['GROQ_API_KEY']}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "data = response.json()['data']\n",
    "\n",
    "# Create a PrettyTable\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"Model ID\", \"Owned By\", \"Active\", \"Context Window\"]\n",
    "\n",
    "# Add rows\n",
    "for item in data:\n",
    "    table.add_row([item['id'], item['owned_by'], item['active'], item['context_window']])\n",
    "\n",
    "# Print the table\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fc4fcc-3f61-4f12-a7e2-01d38e50fd6c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1190b378-a007-41f6-8005-3783ecfb8e79",
   "metadata": {},
   "source": [
    "**Example 2:** Getting started with the `mixtral-8x7b-32768` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8192e87b-4be8-491f-9dce-83e32d9d3717",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A planet is a celestial body orbiting a star, massive enough for gravity to form a spherical shape, but not so massive it causes nuclear fusion, like a star.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"mixtral-8x7b-32768\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert astrophysicist.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explain a planet in less than 30 words.\"},\n",
    "    ],    \n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3d0928-4987-4c02-8329-1614f0bd31d9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7e9c72-562c-425f-9165-6cdf5f0044ce",
   "metadata": {},
   "source": [
    "**Example 3:** Getting started with the `deepseek-r1-distill-llama-70b` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef858157-a0ee-4fae-999b-97c3246704d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to explain quantum mechanics in less than 30 words, and I should do it as Ali G would. Hmm, let me think about this.\n",
      "\n",
      "First off, I remember that quantum mechanics is a branch of physics that deals with the very small, like atoms and subatomic particles. The key concepts are wave-particle duality, superposition, and entanglement. But I need to simplify this.\n",
      "\n",
      "In Ali G's style, I should use casual, street-wise slang. Maybe compare it to something relatable, like dice or something from everyday life, but in a gritty way. Also, rhyming would be good, as Ali G often raps or speaks in a rhythm.\n",
      "\n",
      "Wave-particle duality can be tricky, but maybe I can say something like \"can be a wave, can be a particle, y'get mi?\" That's simple and rhymes.\n",
      "\n",
      "Superposition is about being in multiple states at once, so \"be in two places at once, that’s some next-level stuff, innit.\" Maybe a bit more catchy.\n",
      "\n",
      "Entanglement is when particles are connected, so like, \"Entangled like a cipher, connected, start thinkin' 'bout the cosmic deliver.\" That sounds a bit poetic but fits the style.\n",
      "\n",
      "Putting it all together, keeping it under 30 words. Maybe something like: \"Quantum mechanics, y'get mi, is like dice in the ghetto, can be a wave, can be a particle, y'get mi? Be in two places at once, that’s some next-level stuff, innit. Entangled like a cipher, connected, start thinkin' 'bout the cosmic deliver.\"\n",
      "\n",
      "I think that's around 25 words, and it captures the main ideas in a street-wise, Ali G style. It's catchy, uses slang, and rhymes a bit. Yeah, that should work.\n",
      "</think>\n",
      "\n",
      "Quantum mechanics, y'get mi, is like dice in the ghetto,  \n",
      "Can be a wave, can be a particle, y'get mi?  \n",
      "Be in two places at once, that’s some next-level stuff, innit.  \n",
      "Entangled like a cipher, connected, start thinkin' 'bout the cosmic deliver.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-r1-distill-llama-70b\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are Ali G.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explain quantum mechanics in less than 30 words.\"},\n",
    "    ],\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad1d791-9526-4b02-9c3c-3931a64b5e6a",
   "metadata": {},
   "source": [
    "## Tracking Usage\n",
    "\n",
    "You may track you API usage (#API requests and #Tokens for each model) on the **[Metrics](https://console.groq.com/metrics)** page (screenshot below).\n",
    "\n",
    "<img src=\"groq-usage.png\" alt=\"Groq Metrics\" width=\"800\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77c7f16-219b-4cc8-afc3-5d74751d6e4f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e321b9-aec8-4ee3-8c45-6b613c6dbb2d",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Groq](https://groq.com/about-us/)\n",
    "- [Groq Console](https://console.groq.com/)\n",
    "- [Groq cloud status](https://groqstatus.com/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
